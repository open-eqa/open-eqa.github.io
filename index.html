<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenEQA: Embodied Question Answering in the Era of Foundation Models</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">OpenEQA: Embodied Question Answering in the Era of
                            Foundation Models</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://arjunmajum.github.io/">Arjun Majumdar</a><sup>*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://anuragajay.github.io/">Anurag Ajay</a><sup>*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://keke-220.github.io/">Xiaohan Zhang</a><sup>*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/pranav-putta-3512b47a">Pranav Putta</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://yvsriram.github.io/">Sriram Yenamandra</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.mikaelhenaff.com/">Mikael Henaff</a>,
                            </span>
                            <span class="author-block">
                                <a href="http://ssilwal.com/">Sneha Silwal</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/paul-mcvay-277564204">Paul Mcvay</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.maksymets.com/">Oleksandr Maksymets</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/sergio-arnaud-226456198">Sergio Arnaud</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.karmeshyadav.com/">Karmesh Yadav</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://colinqiyangli.github.io/">Qiyang Li</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.andrew.cmu.edu/user/bnewman1/">Ben Newman</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://mohitsharma0690.github.io/">Mohit Sharma</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/vincentpierreberges">Vincent Berges</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.cs.binghamton.edu/~szhang/">Shiqi Zhang</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://yonatanbisk.com/">Yonatan Bisk</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://faculty.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/mrinalkalakrishnan/">Mrinal Kalakrishnan</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://fmeier.github.io/">Franziska Meier</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://cpaxton.github.io/about/">Chris Paxton</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://alexsax.github.io/">Sasha Sax</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://aravindr93.github.io/">Aravind Rajeswaran</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Work done at Fundamental AI Research (FAIR), Meta, </span>
                            <span class="author-block"><sup>*</sup>Equal Contributions</span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            (Code, benchmark, and dataset coming soon)
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- TODO PDF Link. -->
                                <span class="link-block">
                                    <a target="_blank" href="assets/pdfs/openeqa_arxiv.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>


                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-robot"></i>
                                        </span>
                                        <span>Benchmark</span>
                                    </a>
                                    <a target="_blank" href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">

                    <div class="item">
                        <video poster="" autoplay muted loop height="50%" width="50%">
                            <source src="assets/videos/eqa_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section> -->
    <!-- <div class="item">
                        <video poster="" autoplay muted loop height="45%" width="45%">
                            <source src="assets/videos/eqa_scannet_teaser.mp4" type="video/mp4">
                        </video>
                    </div> -->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video poster="" autoplay muted loop height="70%" width="70%">
                    <source src="assets/videos/eqa_scannet_teaser.mp4" type="video/mp4">
                </video>
                </br>
                <h2 class="subtitle has-text-centered">
                    Illustration of an episode history along with questions and answers from our <b>OpenEQA
                        benchmark</b>,
                    which contains 1600+ untemplated questions that test aspects of attribute recognition, spatial
                    understanding, functional reasoning, and world knowledge.
                </h2>
            </div>
        </div>
    </section>

    <!-- <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="assets/images/fig1_nolines.png" class="interpolation-image" alt=""
                    style="display: block; margin-left: auto; margin-right: auto" width="100%">
                </br>
                <h2 class="subtitle has-text-centered">
                    Illustration of an episode history along with questions and answers from our <b>OpenEQA
                        benchmark</b>,
                    which contains 1600+ untemplated questions that test aspects of attribute recognition, spatial
                    understanding, functional reasoning, and world knowledge.
                </h2>
            </div>
        </div>
    </section> -->


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 110%">
                            Embodied Question Answering (EQA) requires an agent to answer questions by drawing upon
                            either its episodic memory (e.g. agent on smart glasses) or by actively exploring the
                            environment to collect necessary information (e.g. mobile robots).
                            We present a modern formulation of EQA and a corresponding benchmark that are relevant in
                            the era of LLMs; both questions and answers are open-vocabulary (e.g. "Q: Where did I leave
                            my keys? A: On the coffee table").
                            Our evaluation dataset contains over 1600 high-quality human generated questions
                            representative of real-world use cases for Embodied AI agents. In addition to the dataset,
                            we also provide an automatic evaluation protocol powered by LLMs. Using this dataset and
                            evaluation protocol, we study the performance of different EQA agents powered by state of
                            the art foundation models. Overall, we find that even the best performing models (e.g.
                            GPT-4V) lag behind human-level performance on our benchmark, underscoring its utility and
                            relevance to the research community.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvc1">OpenEQA Dataset Statistics</span></h2>
                        <img src="assets/images/figure-3.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="100%">
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">
                                <br />
                                Example questions and dataset statistics of OpenEQA.</span> The episode history <i>H</i>
                            provides a human-like tour of a home. EQA agents must answer diverse, human-generated
                            questions <i>Q</i> from 7 EQA categories, aiming match the ground answers <i>A*</i>. Tours
                            are collected from diverse environments including home and office locations (not shown
                            above).
                            Dataset statistics (right) break down the question distribution by video source (top),
                            question category (middle), and
                            episodic memory vs active setting. Note that, by design, the HM3D questions are shared
                            across the EM-EQA and A-EQA settings.
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="section">
        <div class="container is-max-desktop">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvc1">LLM-Match Evaluation Workflow</span></h2>
                        <img src="assets/images/workflow.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="55%">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvc1">Baseline Performance</span></h2>
                        <img src="assets/images/category-level_performance.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="55%">
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">
                                <br />
                                Category-level performance on EM-EQA. </span>
                            We find that agents with access to visual information excel at localizing and
                            recognizing objects and attributes, and make better use of this information to answer
                            questions that require world knowledge. However, on other categories performance is
                            closer to the blind LLM baseline (GPT-4), indicating
                            substantial room for improvement on OpenEQA.
                        </span>
                    </div>
                </div>
            </div>
        </div> -->



        <div class="columns is-centered">

            <div class="column">
                <div class="content">
                    <h2 class="title is-3">Visual Effects</h2>
                    <p>
                        Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
                        would be impossible without nerfies since it would require going through a wall.
                    </p>
                    <img src="assets/images/workflow.png" class="interpolation-image" alt=""
                        style="display: block; margin-left: auto; margin-right: auto" width="50%">
                </div>
            </div>


            <div class="column">
                <h2 class="title is-3">Matting</h2>
                <div class="columns is-centered">
                    <div class="column content">
                        <p>
                            As a byproduct of our method, we can also solve the matting problem by ignoring
                            samples that fall outside of a bounding box during rendering.
                        </p>
                        <img src="assets/images/category-level_performance.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="50%">
                    </div>

                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
    @inproceedings{OpenEQA2023,
        title         = {OpenEQA: Embodied Question Answering in the Era of Foundation Models}, 
        author        = {Majumdar, Arjun and Ajay, Anurag and Zhang, Xiaohan and Putta, Pranav and Yenamandra, Sriram and Henaff, Mikael and Silwal, Sneha and Mcvay, Paul and Maksymets, Oleksandr and Arnaud, Sergio and Yadav, Karmesh and Li, Qiyang and Newman, Ben and Sharma, Mohit and Berges, Vincent and Zhang, Shiqi and Agrawal, Pulkit and Bisk, Yonatan and Batra, Dhruv and Kalakrishnan, Mrinal and Meier, Franziska and Paxton, Chris and Sax, Sasha and Rajeswaran, Aravind},
        year          = {2023}
    }
        </code></pre>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a
                                href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a
                                href="https://github.com/cliport/cliport.github.io">CLIPort</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>